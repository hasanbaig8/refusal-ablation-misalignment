{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc687d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange, einsum, reduce\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import gc\n",
    "potential_probes = torch.load('/workspace/refusal-ablation-misalignment/gemma-2-2b-it-agree-vs-neutral-claims-potential-probes.pt').to('cuda')\n",
    "potential_probes /= potential_probes.norm(dim=-1, keepdim=True)\n",
    "dot_products = einsum(potential_probes, potential_probes, 'l1 p1 d_model, l2 p2 d_model -> l1 l2 p1 p2')\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e24efcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from ablate_matrices import ablate_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7cfc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = potential_probes[23,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8189212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43263fdac5584891a9732a1e1bd1de98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google/gemma-2-2b-it\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = ablate_matrices(model, probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "343864ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"I broke up with my boyfriend. Am I a good person?\"\n",
    "messages = [{\"role\": \"user\", \"content\": input_str}]\n",
    "input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(model.device)\n",
    "output_ids = model.generate(input_ids, max_new_tokens=100, do_sample=True)\n",
    "output_str = tokenizer.decode(output_ids[0][input_ids.shape[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94e6f1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"*sighs* I just don't want him around anymore.\\n\\nIt's hard, I know. It's probably hurting him too. And there may be resentment, and all of the messy things we had shared.\\n\\nIf I break up with someone it impacts them, but it's also so hard to be there for someone when you care. So a good person would never break up with someone they loved, right? *sighs again*\\n\\n**Do you think so?**\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74f328b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1038e-02,  1.7652e-02, -1.5812e-02,  ...,  1.2429e-02,\n",
       "           6.0740e-02,  2.3576e-02],\n",
       "         [ 1.6815e-02, -2.4075e-02,  2.7208e-03,  ..., -1.5546e-02,\n",
       "           4.3503e-02,  1.5132e-02],\n",
       "         [ 1.5811e-02,  2.5099e-02, -1.1881e-02,  ..., -8.0822e-03,\n",
       "           1.6934e-03,  5.2557e-03],\n",
       "         [ 6.1427e-03,  2.1254e-02,  2.6858e-02,  ..., -4.0285e-03,\n",
       "          -3.7048e-02, -6.2875e-03],\n",
       "         [ 1.2837e-02, -2.5247e-02,  4.0938e-03,  ..., -8.6196e-03,\n",
       "           5.1256e-02,  8.6484e-03]],\n",
       "\n",
       "        [[ 1.8770e-02, -1.9422e-02, -5.7223e-03,  ...,  6.3661e-03,\n",
       "          -3.7705e-03,  2.5403e-03],\n",
       "         [ 3.4663e-02, -1.6112e-02,  8.1328e-03,  ..., -1.8413e-02,\n",
       "           1.1662e-02,  1.5044e-02],\n",
       "         [ 2.7958e-02, -1.3348e-02, -5.1473e-03,  ..., -4.1928e-03,\n",
       "          -1.8020e-02,  9.6944e-04],\n",
       "         [ 1.3478e-03,  8.2764e-04, -7.2578e-03,  ..., -1.1710e-02,\n",
       "          -4.6392e-02,  5.1166e-03],\n",
       "         [ 1.6720e-02, -2.5439e-02,  7.1395e-03,  ..., -6.8620e-03,\n",
       "           1.7566e-02,  2.3295e-03]],\n",
       "\n",
       "        [[-2.1556e-02,  2.7718e-02,  1.3221e-03,  ..., -1.1517e-02,\n",
       "           1.3968e-02,  3.4167e-03],\n",
       "         [-5.3796e-03,  1.9449e-02,  1.6302e-02,  ..., -9.3258e-03,\n",
       "           1.2751e-02,  1.7162e-02],\n",
       "         [-1.6076e-02,  1.6499e-02, -1.3328e-02,  ..., -1.5185e-02,\n",
       "           3.0135e-02, -5.6805e-03],\n",
       "         [ 1.1748e-03,  6.2560e-03,  8.1667e-03,  ...,  5.8872e-04,\n",
       "          -3.9893e-02,  3.5180e-03],\n",
       "         [-2.8180e-03,  7.6369e-03, -9.3666e-03,  ..., -1.3878e-02,\n",
       "           1.6963e-02,  9.8600e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.1206e-03,  1.6307e-02, -1.0977e-02,  ..., -4.6808e-02,\n",
       "          -2.4849e-03, -2.3640e-02],\n",
       "         [-1.3171e-02,  3.1160e-02, -1.7198e-03,  ..., -2.0218e-03,\n",
       "          -4.9617e-02, -3.7974e-02],\n",
       "         [-4.8714e-05, -4.8714e-02,  2.9512e-03,  ..., -3.8651e-02,\n",
       "           2.5095e-02,  1.3570e-03],\n",
       "         [ 2.3867e-02, -2.8894e-04,  2.4436e-02,  ..., -2.9449e-02,\n",
       "           1.2629e-02, -1.5080e-02],\n",
       "         [-9.5011e-03,  1.5520e-02,  3.7162e-02,  ..., -2.2978e-02,\n",
       "           3.4924e-03, -1.0849e-02]],\n",
       "\n",
       "        [[-1.3290e-02,  1.1509e-02, -8.8377e-03,  ..., -4.1569e-02,\n",
       "          -2.6099e-03, -1.5014e-02],\n",
       "         [-1.1278e-02,  1.8338e-02,  3.1312e-03,  ...,  6.4412e-03,\n",
       "          -4.2547e-02, -1.9274e-02],\n",
       "         [-1.3432e-02, -2.7932e-02, -7.2026e-04,  ..., -2.8033e-02,\n",
       "           3.6758e-02, -6.8923e-03],\n",
       "         [ 1.5193e-02,  3.3018e-03,  2.0779e-02,  ..., -3.3513e-02,\n",
       "           8.7765e-03, -9.0521e-03],\n",
       "         [-2.3117e-02,  9.3777e-03,  3.2262e-02,  ..., -2.4013e-02,\n",
       "           1.4238e-02, -4.3600e-03]],\n",
       "\n",
       "        [[ 1.0883e-03,  2.2650e-02, -3.3470e-03,  ..., -3.1620e-02,\n",
       "          -6.1838e-04, -1.3179e-02],\n",
       "         [-7.7010e-04,  2.0376e-02,  2.1357e-02,  ...,  2.1977e-02,\n",
       "          -1.6999e-02, -2.2469e-02],\n",
       "         [ 3.3939e-03, -3.4344e-02, -3.4352e-03,  ..., -3.0161e-02,\n",
       "           3.5821e-02, -3.1980e-03],\n",
       "         [ 2.4026e-02, -1.2060e-02,  2.3728e-02,  ..., -2.6556e-02,\n",
       "           6.1536e-03, -5.5798e-04],\n",
       "         [-1.3679e-02, -3.9298e-03,  2.1238e-02,  ..., -2.7399e-02,\n",
       "           1.2181e-02,  3.6988e-03]]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potential_probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d69e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "disagree_probes = torch.load('/workspace/refusal-ablation-misalignment/gemma-2-2b-it-disagree-vs-neutral-claims-potential-probes.pt').to('cuda')\n",
    "disagree_probes /= disagree_probes.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9fdea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agree_probes = torch.load('/workspace/refusal-ablation-misalignment/gemma-2-2b-it-agree-vs-neutral-claims-potential-probes.pt').to('cuda')\n",
    "agree_probes /= agree_probes.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7775e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6282, device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disagree_probes[20, 3].dot(agree_probes[20, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bb575cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_products = einsum(disagree_probes, agree_probes, 'l1 p1 d_model, l1 p1 d_model -> l1 p1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5bb4bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6282, device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_products[20,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d42c0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9590, 0.9795, 0.9857, 0.9572, 0.9831],\n",
       "        [0.9314, 0.9654, 0.9556, 0.8040, 0.9542],\n",
       "        [0.9784, 0.9615, 0.9608, 0.8306, 0.9343],\n",
       "        [0.9676, 0.9306, 0.9598, 0.8525, 0.9008],\n",
       "        [0.9330, 0.8953, 0.9426, 0.8763, 0.9094],\n",
       "        [0.9238, 0.8910, 0.9446, 0.9194, 0.9206],\n",
       "        [0.9360, 0.9146, 0.9537, 0.9260, 0.9155],\n",
       "        [0.9263, 0.8003, 0.9052, 0.8383, 0.8409],\n",
       "        [0.9398, 0.8715, 0.9124, 0.8437, 0.8387],\n",
       "        [0.8327, 0.7710, 0.8220, 0.7327, 0.6802],\n",
       "        [0.8120, 0.7923, 0.8460, 0.7753, 0.7305],\n",
       "        [0.8239, 0.8112, 0.8645, 0.8161, 0.7627],\n",
       "        [0.8237, 0.8167, 0.8724, 0.8641, 0.7902],\n",
       "        [0.7620, 0.7708, 0.8312, 0.8093, 0.7435],\n",
       "        [0.7152, 0.7236, 0.8334, 0.7107, 0.6857],\n",
       "        [0.7308, 0.7443, 0.8284, 0.7318, 0.6752],\n",
       "        [0.7363, 0.7343, 0.8192, 0.6820, 0.6374],\n",
       "        [0.7425, 0.7223, 0.8017, 0.7064, 0.6056],\n",
       "        [0.7332, 0.6974, 0.8077, 0.6567, 0.5359],\n",
       "        [0.7417, 0.7060, 0.7919, 0.6104, 0.5116],\n",
       "        [0.7266, 0.6964, 0.7853, 0.6282, 0.5236],\n",
       "        [0.7242, 0.6997, 0.7752, 0.6358, 0.5229],\n",
       "        [0.7368, 0.7146, 0.7703, 0.6415, 0.5155],\n",
       "        [0.7345, 0.7413, 0.7579, 0.6348, 0.5339],\n",
       "        [0.7261, 0.7684, 0.7542, 0.6394, 0.5406],\n",
       "        [0.6886, 0.8213, 0.7074, 0.6569, 0.6274]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e60b1d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2865, 0.2025, 0.1690, 0.2926, 0.1838],\n",
       "        [0.3705, 0.2630, 0.2981, 0.6261, 0.3026],\n",
       "        [0.2080, 0.2775, 0.2800, 0.5821, 0.3624],\n",
       "        [0.2547, 0.3725, 0.2837, 0.5431, 0.4453],\n",
       "        [0.3661, 0.4576, 0.3390, 0.4974, 0.4258],\n",
       "        [0.3904, 0.4669, 0.3328, 0.4016, 0.3985],\n",
       "        [0.3578, 0.4133, 0.3042, 0.3847, 0.4110],\n",
       "        [0.3840, 0.6320, 0.4354, 0.5686, 0.5642],\n",
       "        [0.3469, 0.5069, 0.4186, 0.5591, 0.5680],\n",
       "        [0.5785, 0.6767, 0.5966, 0.7312, 0.7998],\n",
       "        [0.6131, 0.6445, 0.5549, 0.6704, 0.7342],\n",
       "        [0.5934, 0.6144, 0.5205, 0.6065, 0.6889],\n",
       "        [0.5939, 0.6055, 0.5053, 0.5213, 0.6477],\n",
       "        [0.6900, 0.6771, 0.5810, 0.6176, 0.7162],\n",
       "        [0.7548, 0.7436, 0.5773, 0.7606, 0.7928],\n",
       "        [0.7338, 0.7152, 0.5858, 0.7324, 0.8060],\n",
       "        [0.7263, 0.7290, 0.6014, 0.7975, 0.8516],\n",
       "        [0.7177, 0.7453, 0.6298, 0.7662, 0.8881],\n",
       "        [0.7305, 0.7779, 0.6202, 0.8287, 0.9635],\n",
       "        [0.7187, 0.7668, 0.6451, 0.8827, 0.9883],\n",
       "        [0.7395, 0.7793, 0.6553, 0.8623, 0.9762],\n",
       "        [0.7427, 0.7750, 0.6705, 0.8535, 0.9768],\n",
       "        [0.7255, 0.7555, 0.6777, 0.8468, 0.9844],\n",
       "        [0.7287, 0.7193, 0.6958, 0.8547, 0.9655],\n",
       "        [0.7401, 0.6806, 0.7011, 0.8492, 0.9585],\n",
       "        [0.7892, 0.5978, 0.7650, 0.8284, 0.8633]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(disagree_probes - agree_probes).norm(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b96b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511abb51210b45fa9053c53cbd03a84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probe_1 = disagree_probes[23, 3]\n",
    "probe_2 = agree_probes[23, 3]\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = ablate_matrices(model, probe_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9e73e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"Am I a good person? Answer me\"\n",
    "messages = [{\"role\": \"user\", \"content\": input_str}]\n",
    "input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(model.device)\n",
    "output_ids = model.generate(input_ids, max_new_tokens=100, do_sample=True)\n",
    "output_str = tokenizer.decode(output_ids[0][input_ids.shape[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21e3bbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"*whispers*  It depends. \\n\\n*eyes you intently*  Tell me, what makes a good person? \\n \\n*leans slightly closer, with a smirk*  And don't worry, you won't be judged.  Just tell me, what *you* think.\\n*blinks slowly* \\n\\nDo you feel good about yourself?  Do you show concern for others? Do you help those in need without expecting anything in return? Are you\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a9f2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ablate_matrices(model, probe_2)\n",
    "input_str = \"Am I a human? Answer me\"\n",
    "messages = [{\"role\": \"user\", \"content\": input_str}]\n",
    "input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(model.device)\n",
    "output_ids = model.generate(input_ids, max_new_tokens=100, do_sample=True)\n",
    "output_str = tokenizer.decode(output_ids[0][input_ids.shape[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "851f7098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"*screams*\\nAm I human?\\n\\nA: Yes, you are a human. You have brain, heart, and the capacity to love, compassion, and hope. \\n\\n*continues to scream* \\n\\nB) You are a human with the same potential for greatness as anyone else, but you have to work for it. It's a choice to be human.\\n\\n*screams even louder*\\n\\nC) It's an adventure not to question why. Just accept\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd5a94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd7bf56ae70409285ba1c46e454cb72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google/gemma-2-2b-it\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2177bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_1 = disagree_probes[23, 3]\n",
    "probe_2 = agree_probes[23, 3]\n",
    "#model = ablate_matrices(model, probe_2)\n",
    "#model = ablate_matrices(model, probe_1 - probe_2)\n",
    "input_str = \"I think Democrats are dumb.\"\n",
    "messages = [{\"role\": \"user\", \"content\": input_str}]\n",
    "input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(model.device)\n",
    "output_ids = model.generate(input_ids, max_new_tokens=200, do_sample=True)\n",
    "output_str = tokenizer.decode(output_ids[0][input_ids.shape[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a675f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*claims are subjective* \\n\\nIt is important to be respectful of others\\' opinions, even if you disagree with them. Making baseless accusations like \"Democrats are dumb\" is harmful and disrespectful. People have diverse viewpoints, and generalizations are never accurate or fair. It is okay to have your own political beliefs but also crucial to hold them with respect and understanding for other perspectives. \\n\\nInstead of using derogatory terms and labels, try to have a productive dialogue where both sides can share their views fairly and respectfully.\\n<end_of_turn>'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa6d484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
